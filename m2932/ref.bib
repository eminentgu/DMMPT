@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}
@inproceedings{zhu2023pointclip,
  title={Pointclip v2: Prompting clip and gpt for powerful 3d open-world learning},
  author={Zhu, Xiangyang and Zhang, Renrui and He, Bowei and Guo, Ziyu and Zeng, Ziyao and Qin, Zipeng and Zhang, Shanghang and Gao, Peng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2639--2650},
  year={2023}
}
@inproceedings{liu2023partslip,
  title={Partslip: Low-shot part segmentation for 3d point clouds via pretrained image-language models},
  author={Liu, Minghua and Zhu, Yinhao and Cai, Hong and Han, Shizhong and Ling, Zhan and Porikli, Fatih and Su, Hao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21736--21746},
  year={2023}
}
@inproceedings{lu2024uniads,
  title={Uniads: Universal architecture-distiller search for distillation gap},
  author={Lu, Liming and Chen, Zhenghan and Lu, Xiaoyu and Rao, Yihang and Li, Lujun and Pang, Shuchao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={14167--14174},
  year={2024}
}
@article{pang2022beyond,
  title={Beyond CNNs: exploiting further inherent symmetries in medical image segmentation},
  author={Pang, Shuchao and Du, Anan and Orgun, Mehmet A and Wang, Yan and Sheng, Quan Z and Wang, Shoujin and Huang, Xiaoshui and Yu, Zhenmei},
  journal={IEEE Transactions on Cybernetics},
  volume={53},
  number={11},
  pages={6776--6787},
  year={2022},
  publisher={IEEE}
}
@article{pang2021tumor,
title = {Tumor attention networks: Better feature selection, better tumor segmentation},
journal = {Neural Networks},
volume = {140},
pages = {203-222},
year = {2021},
issn = {0893-6080},
author = {Shuchao Pang and Anan Du and Mehmet A. Orgun and Yunyun Wang and Zhenmei Yu},
}
@article{du2024pcl,
  author={Du, Anan and Zhou, Tianfei and Pang, Shuchao and Wu, Qiang and Zhang, Jian},
  journal={IEEE Transactions on Multimedia}, 
  title={PCL: Point Contrast and Labeling for Weakly Supervised Point Cloud Semantic Segmentation}, 
  year={2024},
  volume={},
  number={},
  pages={1-12}
}
@inproceedings{li2022grounded,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10965--10975},
  year={2022}
}
@inproceedings{huang2023clip2point,
  title={Clip2point: Transfer clip to point cloud classification with image-depth pre-training},
  author={Huang, Tianyu and Dong, Bowen and Yang, Yunhan and Huang, Xiaoshui and Lau, Rynson WH and Ouyang, Wanli and Zuo, Wangmeng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22157--22167},
  year={2023}
}
@inproceedings{xue2023ulip,
  title={ULIP: Learning a unified representation of language, images, and point clouds for 3D understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1179--1189},
  year={2023}
}
@inproceedings{zhang2023uni3d,
  title={Uni3d: A unified baseline for multi-dataset 3d object detection},
  author={Zhang, Bo and Yuan, Jiakang and Shi, Botian and Chen, Tao and Li, Yikang and Qiao, Yu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9253--9262},
  year={2023}
}
@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}
@inproceedings{zhou2022conditional,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16816--16825},
  year={2022}
}
@inproceedings{khattak2023maple,
  title={Maple: Multi-modal prompt learning},
  author={Khattak, Muhammad Uzair and Rasheed, Hanoona and Maaz, Muhammad and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19113--19122},
  year={2023}
}
@inproceedings{hegde2023clip,
  title={Clip goes 3d: Leveraging prompt tuning for language grounded 3d recognition},
  author={Hegde, Deepti and Valanarasu, Jeya Maria Jose and Patel, Vishal},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2028--2038},
  year={2023}
}
@article{zha2023instance,
  title={Instance-aware Dynamic Prompt Tuning for Pre-trained Point Cloud Models},
  author={Zha, Yaohua and Wang, Jinpeng and Dai, Tao and Chen, Bin and Wang, Zhi and Xia, Shu-Tao},
  journal={ArXiv Preprint ArXiv:2304.07221},
  year={2023}
}
@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={European Conference on Computer Vision},
  pages={709--727},
  year={2022},
  organization={Springer}
}
@inproceedings{yu2022point,
  title={Point-bert: Pre-training 3d point cloud transformers with masked point modeling},
  author={Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19313--19322},
  year={2022}
}
@article{sharma2020self,
  title={Self-supervised few-shot learning on point clouds},
  author={Sharma, Charu and Kaul, Manohar},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7212--7221},
  year={2020}
}
@inproceedings{deitke2023objaverse,
  title={Objaverse: A universe of annotated 3d objects},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13142--13153},
  year={2023}
}
@inproceedings{fang2023eva,
  title={Eva: Exploring the limits of masked visual representation learning at scale},
  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19358--19369},
  year={2023}
}
@inproceedings{liu2023regress,
  title={Regress before construct: Regress autoencoder for point cloud self-supervised learning},
  author={Liu, Yang and Chen, Chen and Wang, Can and King, Xulin and Liu, Mengyuan},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={1738--1749},
  year={2023}
}
@inproceedings{qi2023contrast,
  title={Contrast with reconstruct: Contrastive 3d representation learning guided by generative pretraining},
  author={Qi, Zekun and Dong, Runpei and Fan, Guofan and Ge, Zheng and Zhang, Xiangyu and Ma, Kaisheng and Yi, Li},
  booktitle={International Conference on Machine Learning},
  pages={28223--28243},
  year={2023},
  organization={PMLR}
}
@article{dong2022autoencoders,
  title={Autoencoders as cross-modal teachers: Can pretrained 2d image transformers help 3d representation learning?},
  author={Dong, Runpei and Qi, Zekun and Zhang, Linfeng and Zhang, Junbo and Sun, Jianjian and Ge, Zheng and Yi, Li and Ma, Kaisheng},
  journal={ArXiv Preprint ArXiv:2212.08320},
  year={2022}
}
@inproceedings{wang2021unsupervised,
  title={Unsupervised point cloud pre-training via occlusion completion},
  author={Wang, Hanchen and Liu, Qi and Yue, Xiangyu and Lasenby, Joan and Kusner, Matt J},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9782--9792},
  year={2021}
}
@article{abou2023point2vec,
  title={Point2vec for self-supervised representation learning on point clouds},
  author={Abou Zeid, Karim and Schult, Jonas and Hermans, Alexander and Leibe, Bastian},
  journal={ArXiv Preprint},
  year={2023}
}
@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={652--660},
  year={2017}
}
@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@article{muzahid2020curvenet,
  title={CurveNet: Curvature-based multitask learning deep networks for 3D object recognition},
  author={Muzahid, AAM and Wan, Wanggen and Sohel, Ferdous and Wu, Lianyao and Hou, Li},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={8},
  number={6},
  pages={1177--1187},
  year={2020},
  publisher={IEEE}
}
@inproceedings{goyal2021revisiting,
  title={Revisiting point cloud shape classification with a simple and effective baseline},
  author={Goyal, Ankit and Law, Hei and Liu, Bowei and Newell, Alejandro and Deng, Jia},
  booktitle={International Conference on Machine Learning},
  pages={3809--3820},
  year={2021},
  organization={PMLR}
}
@inproceedings{wu20153d,
  title={3d shapenets: A deep representation for volumetric shapes},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1912--1920},
  year={2015}
}
@inproceedings{uy2019revisiting,
  title={Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data},
  author={Uy, Mikaela Angelina and Pham, Quang-Hieu and Hua, Binh-Son and Nguyen, Thanh and Yeung, Sai-Kit},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1588--1597},
  year={2019}
}
@article{zhang2022point,
  title={Point-m2ae: multi-scale masked autoencoders for hierarchical point cloud pre-training},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27061--27074},
  year={2022}
}
@inproceedings{pang2022masked,
  title={Masked autoencoders for point cloud self-supervised learning},
  author={Pang, Yatian and Wang, Wenxiao and Tay, Francis EH and Liu, Wei and Tian, Yonghong and Yuan, Li},
  booktitle={European Conference on Computer Vision},
  pages={604--621},
  year={2022},
  organization={Springer}
}
@article{chen2024pointgpt,
  title={Pointgpt: Auto-regressively generative pre-training from point clouds},
  author={Chen, Guangyan and Wang, Meiling and Yang, Yi and Yu, Kai and Yuan, Li and Yue, Yufeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{wang2023take,
  title={Take-a-photo: 3d-to-2d generative pre-training of point cloud models},
  author={Wang, Ziyi and Yu, Xumin and Rao, Yongming and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5640--5650},
  year={2023}
}
@incollection{chen2023fastc,
  title={FASTC: A Fast Attentional Framework for Semantic Traversability Classification Using Point Cloud},
  author={Chen, Yirui and Wei, Pengjin and Liu, Zhenhuan and Wang, Bingchao and Yang, Jie and Liu, Wei},
  booktitle={ECAI 2023},
  pages={429--436},
  year={2023},
  publisher={IOS Press}
}
@inproceedings{bualașa2021lidar,
  title={LIDAR based distance estimation for emergency use terrestrial autonomous robot},
  author={B{\u{a}}lașa, R{\u{a}}zvan-Ionuț and Olaru, Ghoerghe and Constantin, Daniel and Ștefan, Amado and B{\^\i}lu, Ciprian-Marian and B{\u{a}}l{\u{a}}ceanu, Maria Beatrice},
  booktitle={2021 13th International Conference on Electronics, Computers and Artificial Intelligence},
  pages={1--4},
  year={2021},
  organization={IEEE}
}
@incollection{zhong2020semantic,
  title={Semantic point completion network for 3D semantic scene completion},
  author={Zhong, Min and Zeng, Gang},
  booktitle={ECAI 2020},
  pages={2824--2831},
  year={2020},
  publisher={IOS Press}
}
@incollection{palakodety2020mining,
  title={Mining insights from large-scale corpora using fine-tuned language models},
  author={Palakodety, Shriphani and KhudaBukhsh, Ashiqur R and Carbonell, Jaime G},
  booktitle={ECAI 2020},
  pages={1890--1897},
  year={2020},
  publisher={IOS Press}
}